---
layout: archive
title: "Research"
permalink: /research/
author_profile: true
---
<b>Areas of Interests:</b>
* Computer Vision
* Natural Language Processing
* Large Language Models
* Contrastive Learning
* Generative Adversarial Network
* Speech Processing
* Deep Learning Applications
  
## Accepted for Publication
<hr>
* <a style="text-decoration: none">M. A. Mahtab</a>, & J. Maisha. <b>"Automated Financial Report Detection, Classification and Structure Recognition Using YOLO and SLANet"</b>. In 2024 IEEE International Conference on Future Machine Learning and Data Science (FMLDS), Sydney, Australia. [[Preprint]](http://dx.doi.org/10.13140/RG.2.2.19451.32803) [[Acceptance Email]](https://drive.google.com/file/d/18XNKOY6Ll826sQoH7AaIOsk1XzEHTRF8/view?usp=sharing) 
* J. Maisha, <a style="text-decoration: none">M. A. Mahtab</a>, F. H. Swarnali, T. Tabassum, & M. T. R. Shawon. <b>"Safeguarding Music Artists Through Machine Learning Based Singer Classification"</b>. In 2024 IEEE 17th International Scientific Conference on Informatics (Informatics), Poprad, Slovakia. [[Preprint]](http://dx.doi.org/10.13140/RG.2.2.31083.55849) [[Acceptance Email]](https://drive.google.com/file/d/1vWjRKvOUYLkVuTLlpJtjd47cj0WEJ6pe/view?usp=sharing) 
  
## Under Review
<hr>
* <a style="text-decoration: none">M. A. Mahtab</a>, J. Maisha, M. M. Rahman, & S. K. S. Joy. <b>"An Empirical Study on Utilizing Large Language Models for Bengali Image Caption Generation"</b>. In 2024 27th International Conference on Computer and Information Technology (ICCIT), Cox’s Bazar, Bangladesh.
<details><summary>Abstract</summary><span style="text-align:justify; display:block;"><font size="3">
An exemplary caption not only describes what is happening in a particular image but also denotes intricate traditional objects in the image by their local representative terms through which the native speakers can recognize the object in question. A caption that fails to accomplish the latter is not effective in conveying proper utility. To ensure caption locality, we aim to explore the potential of Large Language Models (LLM) in Bengali image captioning, which have lately shown promising results in English language caption generation. As a first for the Bengali language, we utilized CLIP (Contrastive Language-Image Pre-training) encodings as a prefix to the captions by employing a mapping network, followed by fine-tuning BanglaGPT, a Bengali pre-trained large language model to generate the image captions. Furthermore, we explored vision transformer-based encoders (ViT, Swin) with BanglaGPT as the decoder. The best BanglaGPT-based model outperformed the current benchmark results, with BLEU-1, BLEU-2, BLEU-3, BLEU-4, METEOR, and CIDEr scores of 70.2, 63.9, 58.8, 54.3, 39.2, and 95.9 on the BanglaLekha dataset and 82.4, 76.8, 71.9, 67.4, 36.6, and 76.9 on the BNature dataset.
</font></span><br></details>
* F. H. Swarnali, J. Maisha, <a style="text-decoration: none">M. A. Mahtab</a>, M. S. I. Iftikar, & F. M. Shah. <b>"Bengali Multi-class Text Classification via Enhanced Contrastive Learning Techniques"</b>. In 2024 27th International Conference on Computer and Information Technology (ICCIT), Cox’s Bazar, Bangladesh.
<details>
<summary>Abstract</summary>
<span style="text-align:justify; display:block;">
<font size="3">
Bengali, one of South Asia's most frequently spoken languages, poses substantial difficulties in tasks such as sentiment analysis and other forms of text classification due to its intricate grammatical structure. This is not just vital for protecting mental health through precise sentiment analysis, but it also has broader ramifications in sectors where accurately discriminating between fine-grained meanings is critical. Improving classification methods to address these subtle distinctions is a timely necessity for advancing natural language processing in Bengali. Our study aims to advance the field of Bengali text classification by implementing Token-level Adversarial Contrastive Training (TACT) and Label-aware Contrastive (LCL) loss, leveraging contrastive learning methods. The two new losses distinguished fine-grained text better, compared to our previous findings on Contrastive Adversarial Training (CAT) and Supervised Contrastive Loss (SCL). For binary class classification, TACT reached an F1-score of 98% outperforming CAT and LCL and setting a new benchmark on the Rokomari Book Review (RBR) dataset. For multi-class classification, TACT achieved an F1-score of 91%, matching the current benchmark on the Bengali Hate Speech (BHS-M) dataset. Furthermore, our custom Bengali multi-class text classification dataset, Daraz Product Review (DPR) further contributes to the field.
</font>
</span><br>
</details>
## Ongoing Research
<hr>
* BN-COCO: A Multi-Purpose Bengali Dataset and LLM-GAN Based Image Captioning System Leveraging Supervised and Unsupervised Learning.
* Explainable Contrastive Learning Approach for Spam Review Classification Utilizing Large Language Models.

## Research In Early Stage
<hr>
* Harnessing Large Language Models for Bengali Social Media Post Text Summarization.
* Plagarism Detection for Old Bengali Songs.
* Sub Dialect Detection and Machine Translation for Bengali Language.
* LLMs for Financial Report Analysis.

__________________________________________________